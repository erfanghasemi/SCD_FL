{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erfanghasemi/SCD_FL/blob/main/GoogleNet_model_PyTorch_8_Types.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfazvYRP6NG_"
      },
      "source": [
        "# **Pure GoogleNet with PyTorch**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bDv-lfJxuOz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import json\n",
        "import urllib.request\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-mqsSw9asDp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHn7WHP6x35y"
      },
      "outputs": [],
      "source": [
        "# Load the GoogleNet (Inception) model\n",
        "model = torchvision.models.googlenet(pretrained=True)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kEmkQid0ZmE"
      },
      "outputs": [],
      "source": [
        "# Load the class index mapping from the JSON file\n",
        "with open('/content/drive/MyDrive/BSc Project/Codes/output.json') as f:\n",
        "    class_idx = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2YLkCq2x-Va"
      },
      "outputs": [],
      "source": [
        "# Preprocessing transformations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6u_sdKaiyBav"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess an image\n",
        "urllib.request.urlretrieve(\n",
        "  'data:image/jpeg;base64,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',\n",
        "   \"image.jpg\")\n",
        "image = Image.open(\"image.jpg\")\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm0FG3j8yLsr"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kcjFhPqzjS9"
      },
      "outputs": [],
      "source": [
        "# Function to get predicted label\n",
        "def get_predicted_label(output_tensor):\n",
        "    _, predicted_idx = output_tensor.max(1)\n",
        "    predicted_label = class_idx[str(predicted_idx.item())][1]\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF-29Xd63wjd"
      },
      "outputs": [],
      "source": [
        "# Get and print predicted label\n",
        "predicted_label = get_predicted_label(output)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63FuA4XS6nxX"
      },
      "source": [
        "# **Modified GoogleNet with Pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets.folder import default_loader\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "mPF08zUMiEqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JazMod25TQTL"
      },
      "outputs": [],
      "source": [
        "# Define the data transformations (you may need to customize this based on your dataset)\n",
        "data_transforms = {\n",
        "    'Trainning Dataset': transforms.Compose([\n",
        "        transforms.Resize(1024),\n",
        "        transforms.CenterCrop(750),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "    'Validation Dataset': transforms.Compose([\n",
        "        transforms.Resize(1024),\n",
        "        transforms.CenterCrop(750),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03wyA-QlT_hs"
      },
      "outputs": [],
      "source": [
        "# Provide the path to your dataset\n",
        "data_dir = '/content/drive/MyDrive/BSc Project/Skin Cancer Datasets/ISIC_2019_Dataset'\n",
        "\n",
        "# Load the dataset using ImageFolder\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['Trainning Dataset', 'Validation Dataset']}\n",
        "\n",
        "# Create data loaders\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=5) for x in ['Trainning Dataset', 'Validation Dataset']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmYWIDhrUSzs"
      },
      "outputs": [],
      "source": [
        "# Number of classes in your dataset\n",
        "num_classes = image_datasets['Trainning Dataset'].classes\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x_M5_2gUTYb"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained GoogleNet model\n",
        "model = models.googlenet(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPvkbqFPaU7p"
      },
      "outputs": [],
      "source": [
        "# Optionally, you can freeze the parameters of the base model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnoJ2lM7Ueh-"
      },
      "outputs": [],
      "source": [
        "# Modify the final fully connected layer for your number of classes\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 2048),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2048, 3),  # 3 classes\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LysOJ0hUsfz"
      },
      "outputs": [],
      "source": [
        "# Set the device (GPU or CPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQOud1zRUyq9"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.015, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urB-rkMGWDuQ"
      },
      "outputs": [],
      "source": [
        "# Training loop (you may need to customize this)\n",
        "num_epochs =3\n",
        "for epoch in range(num_epochs):\n",
        "    for phase in ['Trainning Dataset', 'Validation Dataset']:\n",
        "        if phase == 'Trainning Dataset':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in tqdm(dataloaders[phase], desc=\"Epoch {} - {} is processing\".format(epoch, phase)):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'Trainning Dataset'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'Trainning Dataset':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(image_datasets[phase])\n",
        "        epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLPq1idpWJOf"
      },
      "outputs": [],
      "source": [
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=8, shuffle=True, num_workers=5) for x in ['Trainning Dataset', 'Validation Dataset']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fLPDOmUwAJf"
      },
      "outputs": [],
      "source": [
        "# Optionally, you can freeze the parameters of the base model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0qhnO5zwDqy"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC6weRc-wull"
      },
      "outputs": [],
      "source": [
        "# Training loop (you may need to customize this)\n",
        "num_epochs =3\n",
        "for epoch in range(num_epochs):\n",
        "    for phase in ['Trainning Dataset', 'Validation Dataset']:\n",
        "        if phase == 'Trainning Dataset':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in tqdm(dataloaders[phase], desc=\"Epoch {} - {} is processing\".format(epoch, phase)):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'Trainning Dataset'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'Trainning Dataset':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(image_datasets[phase])\n",
        "        epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF6OvV71xC--"
      },
      "outputs": [],
      "source": [
        "# Assuming 'model' is your PyTorch model\n",
        "# Save the model architecture and parameters\n",
        "os.chdir(\"/content/drive/MyDrive/BSc Project/Codes/Model Weights\")\n",
        "torch.save(model, 'model_V2.pth')\n",
        "\n",
        "# If you want to save only the model's state_dict (parameters), use this:\n",
        "torch.save(model.state_dict(), 'model_state_V2.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference from the loaded model**"
      ],
      "metadata": {
        "id": "gl9eqACllmwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the saved model checkpoint\n",
        "model_checkpoint_path = '/content/drive/MyDrive/BSc Project/Codes/Model Weights/model_V2.pth'\n",
        "\n",
        "# Load the entire model\n",
        "model = torch.load(model_checkpoint_path)\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "QMJWBmG9n_rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "tehGoBL6l4KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the class index mapping from the JSON file\n",
        "with open('/content/drive/MyDrive/BSc Project/Codes/json_lesions.json') as f:\n",
        "    class_idx = json.load(f)"
      ],
      "metadata": {
        "id": "UbbaDjqul5sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to preprocess input data\n",
        "def preprocess_input(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(1024),\n",
        "        transforms.CenterCrop(750),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0).cuda()  # Add a batch dimension\n",
        "    return image"
      ],
      "metadata": {
        "id": "wmOnS1GHl7Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/BSc Project/Skin Cancer Datasets/ISIC_2019_Dataset/Validation Dataset/melanoma/ISIC_0026115.jpg\"\n",
        "input_image = preprocess_input(image_path)"
      ],
      "metadata": {
        "id": "epqrHoszl8Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(input_image)"
      ],
      "metadata": {
        "id": "UgKmT5eJl9RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get predicted label\n",
        "def get_predicted_label(output_tensor):\n",
        "    _, predicted_idx = output_tensor.max(1)\n",
        "    predicted_label = class_idx[str(predicted_idx.item())][1]\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "rh8prT1Ol-di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and print predicted label\n",
        "predicted_label = get_predicted_label(output)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjCp4ycfl_ho",
        "outputId": "02c58f56-2f7b-4004-c5f2-a65ceae0daa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: melanoma\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1aw27HYFYw3xx8-hmIb8XSKsWT_pkve9g",
      "authorship_tag": "ABX9TyPK91nfFzPwGwiY947gQtK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}