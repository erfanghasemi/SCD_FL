{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"11wx_UAqlDS-XQKs2A9LjGLwK8jIpbOB0","authorship_tag":"ABX9TyPfAzEjj0ozoFl44PA+SKtw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","> **Simulate the Federated Learning Process on the pre-traind model**\n","\n"],"metadata":{"id":"qYSTD3j9Li3F"}},{"cell_type":"markdown","source":["# **Import used libraries**"],"metadata":{"id":"od9Jr-OQm0Ea"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzNhBBbP2IHE"},"outputs":[],"source":["!pip install -q flwr[simulation] torch torchvision matplotlib tensorrt scipy"]},{"cell_type":"code","source":["from collections import OrderedDict\n","from typing import Dict, List, Optional, Tuple\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, random_split\n","from torchvision.datasets import ImageFolder\n","from PIL import Image\n","import json\n","\n","import flwr as fl\n","from flwr.common import Metrics"],"metadata":{"id":"xe97CtAi3Jm-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Connecting to Google Drive**\n"],"metadata":{"id":"PodNtxiGLvEt"}},{"cell_type":"markdown","source":["Use `flush_and_unmount` and `force_remount=True` for safe connection.\n","\n","---"],"metadata":{"id":"3qU8zyGZLyVF"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"o1r2nQbmbzi8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Helper functions and information are here**"],"metadata":{"id":"UOv405XqMzP7"}},{"cell_type":"markdown","source":["\n","\n","> Set main learning process parameter\n","\n"],"metadata":{"id":"TQDcTg27NLQl"}},{"cell_type":"code","source":["NUM_CLIENTS = 100\n","BATCH_SIZE = 8\n","LOCAL_CLIENT_EPOCHS = 1\n","NUM_ROUNDS = 2\n","CLASSES = (\"BCC\", \"MEL\", \"NEV\")"],"metadata":{"id":"pz0RC3ho4m1N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","> Check CPU or GPU availability\n","\n"],"metadata":{"id":"QRELEuXHM-dr"}},{"cell_type":"code","source":["DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Try \"cuda\" to train on GPU\n","print(\n","    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",")"],"metadata":{"id":"lPHHzUAltb2C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> Load json file for label mapping"],"metadata":{"id":"d99YAvn9NX6T"}},{"cell_type":"code","source":["# Load the class index mapping from the JSON file\n","label_mapping_json_path = '/content/drive/MyDrive/BSc Project/Codes/json_lesions.json'\n","\n","def load_label_mapping(file_path: str):\n","  with open(file_path) as f:\n","      class_idx = json.load(f)\n","  return class_idx\n","\n","class_idx = load_label_mapping(label_mapping_json_path)"],"metadata":{"id":"dPI5Ep6ah7a5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> Load FL dataset from Google Drive"],"metadata":{"id":"nkx4kxpwNpNw"}},{"cell_type":"code","source":["def load_datasets(num_clients: int):\n","\n","    transform = transforms.Compose([\n","        transforms.Resize(1024),\n","        transforms.CenterCrop(750),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    trainset = ImageFolder(root='/content/drive/MyDrive/BSc Project/Skin Cancer Datasets/ISIC_2019_Dataset/FL Training Dataset', transform=transform)\n","    testset = ImageFolder(root='/content/drive/MyDrive/BSc Project/Skin Cancer Datasets/ISIC_2019_Dataset/FL Test Dataset', transform=transform)\n","\n","    # Split training set into `num_clients` partitions to simulate different local datasets\n","    partition_size = len(trainset) // num_clients\n","    lengths = [partition_size] * num_clients\n","    lengths[-1] += len(trainset) % num_clients\n","\n","    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n","\n","    # Split each partition into train/val and create DataLoader\n","    trainloaders = []\n","    valloaders = []\n","    for ds in datasets:\n","        len_val = len(ds) // 10  # 10 % validation set\n","        len_train = len(ds) - len_val\n","        lengths = [len_train, len_val]\n","        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n","        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n","        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n","    testloader = DataLoader(testset, batch_size=1)\n","    return trainloaders, valloaders, testloader\n","\n","\n","trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"],"metadata":{"id":"Whf1eGtgaLF7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_parameters(net) -> List[np.ndarray]:\n","    return [val.cpu().numpy() for _, val in net.state_dict().items()]"],"metadata":{"id":"4ZNHPpOtnagD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_parameters(net, parameters: List[np.ndarray]):\n","    params_dict = zip(net.state_dict().keys(), parameters)\n","    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n","    net.load_state_dict(state_dict, strict=True)"],"metadata":{"id":"-qwVvL_LOSe9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(net, trainloader, epochs: int, verbose=False):\n","    \"\"\"Train the network on the training set.\"\"\"\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(net.parameters(), lr=0.00001)\n","    net.train()\n","    for epoch in range(epochs):\n","        correct, total, epoch_loss = 0, 0, 0.0\n","        for images, labels in trainloader:\n","            images, labels = images.to(DEVICE), labels.to(DEVICE)\n","            optimizer.zero_grad()\n","            outputs = net(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            # Metrics\n","            epoch_loss += loss\n","            total += labels.size(0)\n","            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n","        epoch_loss /= len(trainloader.dataset)\n","        epoch_acc = correct / total\n","        if verbose:\n","            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")"],"metadata":{"id":"NraFXLDeqM6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(net, testloader):\n","    \"\"\"Validate the network on the entire test set.\"\"\"\n","    criterion = torch.nn.CrossEntropyLoss()\n","    correct, total, loss = 0, 0, 0.0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n","            outputs = net(images)\n","            loss += criterion(outputs, labels).item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    accuracy = correct / total\n","    return loss, accuracy"],"metadata":{"id":"PxfH7jX7qNfM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> Show some samples from image dataset (bach_size shoud be more than 32)"],"metadata":{"id":"D6Bsvdr9NyR1"}},{"cell_type":"code","source":["images, labels = next(iter(trainloaders[0]))\n","\n","# Reshape and convert images to a NumPy array\n","# matplotlib requires images with the shape (height, width, 3)\n","images = images.permute(0, 2, 3, 1).numpy()\n","# Denormalize\n","images = images / 2 + 0.5\n","\n","# Create a figure and a grid of subplots\n","fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n","\n","# Loop over the images and plot them\n","for i, ax in enumerate(axs.flat):\n","    ax.imshow(images[i])\n","    ax.set_title(CLASSES[labels[i]])\n","    ax.axis(\"off\")\n","\n","# Show the plot\n","fig.tight_layout()\n","plt.show()"],"metadata":{"id":"qTNbv6Lyfwvl","executionInfo":{"status":"ok","timestamp":1693596549666,"user_tz":-210,"elapsed":7,"user":{"displayName":"Mohammaderfan Ghasemi","userId":"03613741105621501267"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# **Client-Side**"],"metadata":{"id":"ls-HXP6oSsq6"}},{"cell_type":"code","source":["class FlowerClient(fl.client.NumPyClient):\n","    def __init__(self, net, trainloader, valloader):\n","        self.net = net\n","        self.trainloader = trainloader\n","        self.valloader = valloader\n","\n","    def get_parameters(self, config):\n","        return get_parameters(self.net)\n","\n","    def fit(self, parameters, config):\n","        set_parameters(self.net, parameters)\n","        train(self.net, self.trainloader, epochs=2)\n","        return get_parameters(self.net), len(self.trainloader), {}\n","\n","    def evaluate(self, parameters, config):\n","        set_parameters(self.net, parameters)\n","        loss, accuracy = test(self.net, self.valloader)\n","        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"],"metadata":{"id":"oU3lB3K6pw4P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def client_fn(cid: str) -> FlowerClient:\n","    \"\"\"Create a Flower client representing a single organization.\"\"\"\n","\n","    # Load model\n","    net = model.to(DEVICE)\n","\n","    # Note: each client gets a different trainloader/valloader, so each client\n","    # will train and evaluate on their own unique data\n","    trainloader = trainloaders[int(cid)]\n","    valloader = valloaders[int(cid)]\n","\n","    # Create a  single Flower client representing a single organization\n","    return FlowerClient(net, trainloader, valloader)"],"metadata":{"id":"PSqUR7--qkpH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n","    # Multiply accuracy of each client by number of examples used\n","    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n","    examples = [num_examples for num_examples, _ in metrics]\n","\n","    # Aggregate and return custom metric (weighted average)\n","    return {\"accuracy\": sum(accuracies) / sum(examples)}"],"metadata":{"id":"0ulRsUQ1xyiQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(\n","    server_round: int,\n","    parameters: fl.common.NDArrays,\n","    config: Dict[str, fl.common.Scalar],\n",") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n","    net = model.to(DEVICE)\n","    set_parameters(net, parameters)  # Update model with the latest parameters\n","    loss, accuracy = test(net, testloader)\n","    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy:.4f}\")\n","    return loss, {\"accuracy\": accuracy}"],"metadata":{"id":"oPF1wXxj3MuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_checkpoint_path = '/content/drive/MyDrive/BSc Project/Codes/Model Weights/model_V2.pth'\n","\n","# Load the entire model\n","model = torch.load(model_checkpoint_path)\n","params = get_parameters(model)\n","\n","def load_model(model_checkpoint_path: str, layer_count: int):\n","  model = torch.load(model_checkpoint_path)\n","  params = get_parameters(model)\n","\n","  # model = keep_last_layers(layer_count, model)\n","  for param in model.parameters():\n","    param.requires_grad = False\n","\n","  all_layers = list(model.children())\n","  num_layers = len(all_layers)\n","  last_three_layers = nn.Sequential(*all_layers[num_layers - layer_count:])\n","\n","  for param in last_three_layers.parameters():\n","    param.requires_grad = True\n","\n","  # for name, param in model.named_parameters():\n","  #   if not param.requires_grad:\n","  #       print(f\"Layer '{name}' is frozen.\")\n","\n","  return model, params\n","\n","model, params = load_model(model_checkpoint_path, 3)"],"metadata":{"id":"I8ihdiqoUiVK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Server-Side**"],"metadata":{"id":"t7N8EwfRS1We"}},{"cell_type":"code","source":["# Create FedAvg strategy\n","strategy = fl.server.strategy.FedAvg(\n","    fraction_fit=0.01,  # Sample 100% of available clients for training\n","    fraction_evaluate=0.01,  # Sample 50% of available clients for evaluation\n","    min_fit_clients=1,  # Never sample less than 10 clients for training\n","    min_evaluate_clients=1,  # Never sample less than 5 clients for evaluation\n","    min_available_clients=1,  # Wait until all 10 clients are available\n","    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n","    initial_parameters=fl.common.ndarrays_to_parameters(params),\n","    evaluate_fn=evaluate,  # Pass the evaluation function\n",")"],"metadata":{"id":"IDuw1r9c4_S7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n","client_resources = None\n","if DEVICE.type == \"cuda\":\n","    client_resources = {\"num_gpus\": 1}"],"metadata":{"id":"5jr3CeuS_GiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Start simulation\n","fl.simulation.start_simulation(\n","    client_fn=client_fn,\n","    num_clients=NUM_CLIENTS,\n","    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n","    strategy=strategy,\n","    client_resources=client_resources,\n",")"],"metadata":{"id":"DU5N-kINrTIh"},"execution_count":null,"outputs":[]}]}