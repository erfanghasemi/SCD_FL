{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63FuA4XS6nxX"
      },
      "source": [
        "# **Import used libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPF08zUMiEqx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets.folder import default_loader\n",
        "import json\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJygAyg-wUiT"
      },
      "source": [
        "# **Connecting to Google Drive**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBYg58S1wW-k"
      },
      "source": [
        "Use `flush_and_unmount` and `force_remount=True` for safe connection.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y5RLIu_wci7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or3lTE47w1iL"
      },
      "source": [
        "# **Parameters and Folders path**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC1jC0c6D7BF"
      },
      "source": [
        "> Set used parameters' value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr3vxBS7xIzr"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 1024  # The size (in pixels) of the images used in the model.\n",
        "CENTER_CROP_SIZE = 750  # The size (in pixels) for center cropping the images.\n",
        "\n",
        "NUM_WORKERS_DATALOADER = 6  # The number of data loader workers for parallel data loading.\n",
        "\n",
        "OUTPUT_FC_UNITS = 2048  # The number of units in the output fully connected layer of the model.\n",
        "\n",
        "BATCH_SIZE_STEP_ZERO = 32  # Batch size used during the first training step.\n",
        "BATCH_SIZE_STEP_ONE = 32  # Batch size used during the second training step.\n",
        "BATCH_SIZE_STEP_EVAL = 32  # Batch size used during model evaluation.\n",
        "\n",
        "LEARNING_RATE_STEP_ZERO = 0.01  # Learning rate used during the first training step.\n",
        "LEARNING_RATE_STEP_ONE = 0.001  # Learning rate used during the second training step.\n",
        "\n",
        "MOMENTUM = 0.9  # Momentum parameter used in the optimization algorithm.\n",
        "\n",
        "NUM_EPOCHS_STEP_ZERO = 5  # Number of training epochs during the first training step.\n",
        "NUM_EPOCHS_STEP_ONE = 5  # Number of training epochs during the second training step.\n",
        "\n",
        "DEFAULT_NUM_CLASS = 3  # Default number of classes for inference; can be changed for different tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD4AKGuBD72x"
      },
      "source": [
        "> Define used folders path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KrkpKARxgrg"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR_PATH = '/content/drive/MyDrive/BSc Project/Skin Cancer Datasets/ISIC_2019_Dataset'\n",
        "MODEL_CHECKPOINT_PATH = '/content/drive/MyDrive/BSc Project/Codes/Model Checkpoints/Base_Model'\n",
        "MAPPING_LABEL_INDEX = '/content/drive/MyDrive/BSc Project/Codes/modified_googlenet_lesions_mapping_labels.json'\n",
        "TRAINING_DATASET_DIR_NAME = 'Trainning Dataset'\n",
        "VALIDATION_DATASET_DIR_NAME = 'Validation Dataset'\n",
        "TEST_DATASET_DIR_NAME = 'Test Dataset'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_yeMafID9B5"
      },
      "source": [
        "> Find the type of device CPU/GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tQkivHS237Z"
      },
      "outputs": [],
      "source": [
        "DEVICE = str(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSM0FbaXDwvh"
      },
      "source": [
        "# **Implement learning and evaluating functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjKplvNFEonT"
      },
      "source": [
        ">  Load dataset and create dataloaders for training and validation processes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt7Z8HU8BwSJ"
      },
      "outputs": [],
      "source": [
        "def load_data(image_size: int,\n",
        "              center_crop_size: int,\n",
        "              dataset_dir_path: str,\n",
        "              train_dataset_dir_path: str,\n",
        "              validation_dataset_dir_path: str,\n",
        "              test_dataset_dir_path: str,\n",
        "              num_workers_dataloader: int,\n",
        "              batch_size: int\n",
        "              ):\n",
        "\n",
        "  # Define the data transformations (you may need to customize this based on your dataset)\n",
        "  data_transforms = {\n",
        "    train_dataset_dir_path : transforms.Compose([\n",
        "          transforms.Resize(image_size),\n",
        "          transforms.CenterCrop(center_crop_size),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      ]),\n",
        "    validation_dataset_dir_path : transforms.Compose([\n",
        "          transforms.Resize(image_size),\n",
        "          transforms.CenterCrop(center_crop_size),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      ]),\n",
        "    test_dataset_dir_path : transforms.Compose([\n",
        "          transforms.Resize(image_size),\n",
        "          transforms.CenterCrop(center_crop_size),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      ]),\n",
        "  }\n",
        "\n",
        "  # Load the dataset using ImageFolder\n",
        "  image_datasets = {x: datasets.ImageFolder(os.path.join(dataset_dir_path, x), data_transforms[x]) for x in \\\n",
        "                   [train_dataset_dir_path, validation_dataset_dir_path, test_dataset_dir_path]}\n",
        "\n",
        "  # Create data loaders\n",
        "  dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=num_workers_dataloader) for x in \\\n",
        "                [train_dataset_dir_path, validation_dataset_dir_path, test_dataset_dir_path]}\n",
        "\n",
        "  # Number of classes in your dataset\n",
        "  num_classes = len(image_datasets['Trainning Dataset'].classes)\n",
        "\n",
        "  return image_datasets, dataloaders, num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0f8dfA1toKe"
      },
      "source": [
        "> Implement a function to preprocess input data for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmOnS1GHl7Iq"
      },
      "outputs": [],
      "source": [
        "def preprocess_input(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(1024),\n",
        "        transforms.CenterCrop(750),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path)\n",
        "    image = transform(image).unsqueeze(0).cuda()  # Add a batch dimension\n",
        "    return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gHwN60iITUJ"
      },
      "source": [
        "> Load model from last checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j2GVQjUA-PJ"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(checkpoints_path: str, device):\n",
        "    try:\n",
        "      last_checkpoint = sorted(os.listdir(checkpoints_path))[-1]\n",
        "    except:\n",
        "      print(\"There is no saved model in this path: {}\".format(checkpoints_path))\n",
        "      return -1\n",
        "\n",
        "    checkpoints_path = os.path.join(checkpoints_path, last_checkpoint)\n",
        "\n",
        "    if device == \"cuda:0\":\n",
        "        model = torch.load(checkpoints_path)\n",
        "        print(\"checkpoint version {} is loaded on GPU\".format(last_checkpoint))\n",
        "\n",
        "    elif device == \"cpu\" :\n",
        "        model = torch.load(checkpoints_path, map_location=torch.device('cpu'))\n",
        "        print(\"checkpoint version {} is loaded on CPU\".format(last_checkpoint))\n",
        "\n",
        "    else:\n",
        "        print(\"Device Type is unknown\")\n",
        "        return -1\n",
        "\n",
        "    model.to(device)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb_zgxsfIPFn"
      },
      "source": [
        "> Save model after training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF6OvV71xC--"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, checkpoints_path: str, epoch_state: int, step_state: int):\n",
        "    try:\n",
        "      last_version = os.listdir(checkpoints_path)[-1].split('_')[-1].split('.')[0]\n",
        "    except:\n",
        "      last_version = 0\n",
        "\n",
        "    model_checkpoint_filename = \"Model\" + \"_\" + \"Checkpoint\" + \"_\" + \"STEP\" + \"_\" + str(step_state) + \"EPOCH\" + \"_\" + str(epoch_state) + \".pth\"\n",
        "\n",
        "    save_path = os.path.join(checkpoints_path, model_checkpoint_filename)\n",
        "\n",
        "    torch.save(model, save_path)\n",
        "    print(\"\\n checkpoint is saved in path: {}\\n\".format(save_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eU1iPypGpNG"
      },
      "source": [
        "> Load pre-trained model and append extra layers to the top of pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBSYICm-Fedy"
      },
      "outputs": [],
      "source": [
        "def load_model(output_fc_units: int, device, checkpoints_path: str, freeze_base_layers: bool, num_classes: int = DEFAULT_NUM_CLASS):\n",
        "\n",
        "  # check last checkpoint if it exists\n",
        "  model = load_checkpoint(checkpoints_path, device)\n",
        "\n",
        "  if model != -1:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = True\n",
        "    return model\n",
        "\n",
        "  # Load a pre-trained GoogleNet model\n",
        "  model = models.googlenet(pretrained=True)\n",
        "\n",
        "  # Optionally, you can freeze the parameters of the base model\n",
        "  if freeze_base_layers:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  # Modify the final fully connected layer for your number of classes\n",
        "  num_features = model.fc.in_features\n",
        "  model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, output_fc_units),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(output_fc_units, num_classes),\n",
        "    nn.Softmax(dim=1),\n",
        "  )\n",
        "  # Set the device (GPU or CPU)\n",
        "  model.to(device)\n",
        "  print(\"Model loaded with pure GoogleNet weights\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oh13n3zH-5-"
      },
      "source": [
        "> Define learning loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0qhnO5zwDqy"
      },
      "outputs": [],
      "source": [
        "def define_loss_opt(learning_rate: int, momentum: int):\n",
        "  # Define loss function and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "  return criterion, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud4rVXDhIEaD"
      },
      "source": [
        "> Define the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC6weRc-wull"
      },
      "outputs": [],
      "source": [
        "def train(num_epoch: int,\n",
        "          model,\n",
        "          train_dataset_dir_path: str,\n",
        "          validation_dataset_dir_path: str,\n",
        "          dataloaders,\n",
        "          image_datasets,\n",
        "          optimizer,\n",
        "          criterion,\n",
        "          device,\n",
        "          checkpoints_path: str,\n",
        "          step: int\n",
        "          ):\n",
        "  save_checkpoint(model , checkpoints_path, -1, -1)\n",
        "  # Training loop (you may need to customize this)\n",
        "  for epoch in range(num_epoch):\n",
        "      for phase in [train_dataset_dir_path, validation_dataset_dir_path]:\n",
        "          if phase == train_dataset_dir_path:\n",
        "              model.train()\n",
        "          else:\n",
        "              model.eval()\n",
        "\n",
        "          running_loss = 0.0\n",
        "          all_labels = []\n",
        "          all_preds = []\n",
        "\n",
        "          for inputs, labels in tqdm(dataloaders[phase], desc=\"Epoch {} - {} is processing\".format(epoch, phase)):\n",
        "              inputs = inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              with torch.set_grad_enabled(phase == train_dataset_dir_path):\n",
        "                  outputs = model(inputs)\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  loss = criterion(outputs, labels)\n",
        "\n",
        "                  if phase == train_dataset_dir_path:\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "              running_loss += loss.item() * inputs.size(0)\n",
        "              all_labels.extend(labels.cpu().numpy())\n",
        "              all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "          epoch_loss = running_loss / len(image_datasets[phase])\n",
        "          epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "          epoch_precision = precision_score(all_labels, all_preds, average='macro')\n",
        "          epoch_recall = recall_score(all_labels, all_preds, average='macro')\n",
        "          epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "          print(f'{phase} Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f} Precision: {epoch_precision:.4f} F1-Score: {epoch_f1:.4f} Recall: {epoch_recall:.4f}')\n",
        "\n",
        "      # Save the model at the end of each epoch\n",
        "      save_checkpoint(model , checkpoints_path, epoch, step)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rguvdAToxpq"
      },
      "source": [
        "> Implement model evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuZ1Dtnpox9I"
      },
      "outputs": [],
      "source": [
        "def evaluation(model, dataloaders, test_dataset_dir_path: str, device):\n",
        "  # Put the model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Initialize lists to store true labels and predicted labels\n",
        "  true_labels = []\n",
        "  predicted_labels = []\n",
        "  test_dataloader = dataloaders[test_dataset_dir_path]\n",
        "\n",
        "  # Iterate through the test dataloader\n",
        "  with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "      for inputs, labels in tqdm(test_dataloader, desc=\"Evaluating in progress... \"):\n",
        "          inputs = inputs.to(device)  # Move data to the device (e.g., GPU)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Forward pass to get model predictions\n",
        "          outputs = model(inputs)\n",
        "          _, preds = torch.max(outputs, 1)  # Get predicted class indices\n",
        "\n",
        "          # Append true labels and predicted labels to lists\n",
        "          true_labels.extend(labels.cpu().numpy())\n",
        "          predicted_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "  # Calculate evaluation metrics\n",
        "\n",
        "  accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "  precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "  recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "  f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "  conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "  print(f'\\nAccuracy: {accuracy:.4f}')\n",
        "  print(f'Precision: {precision:.4f}')\n",
        "  print(f'Recall: {recall:.4f}')\n",
        "  print(f'F1-Score: {f1:.4f}')\n",
        "  print('Confusion Matrix:')\n",
        "  print(conf_matrix)\n",
        "\n",
        "  return accuracy, precision, recall, f1, conf_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQuLvfHcur2b"
      },
      "source": [
        "> Function to get predicted label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh8prT1Ol-di"
      },
      "outputs": [],
      "source": [
        "def get_predicted_label(output_tensor, class_idx):\n",
        "    _, predicted_idx = output_tensor.max(1)\n",
        "    predicted_label = class_idx[str(predicted_idx.item())][1]\n",
        "    return predicted_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy4SfMgjuMVw"
      },
      "source": [
        "> Prediction for a dermoscopic image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwNQ3UNGtO5h"
      },
      "outputs": [],
      "source": [
        "def prediction(image_path: str, mapping_label_index: str):\n",
        "  # Set the model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Load the class index mapping from the JSON file\n",
        "  with open(mapping_label_index) as f:\n",
        "    class_idx = json.load(f)\n",
        "\n",
        "  input_image = preprocess_input(image_path)\n",
        "\n",
        "  # Perform inference\n",
        "  with torch.no_grad():\n",
        "    output = model(input_image)\n",
        "\n",
        "  # get predicted label\n",
        "  predicted_label = get_predicted_label(output, class_idx)\n",
        "  print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "  return predicted_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVbAMxUCKYdf"
      },
      "source": [
        "# **Learning Model Process**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3D4zoDVLN6i"
      },
      "source": [
        "## ***Phase 0: Train only added extra layers***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G0u4e7fL7OA"
      },
      "source": [
        "> Load datasets and create handler for them and # classes of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faCi7qjZDS-N"
      },
      "outputs": [],
      "source": [
        "image_datasets, dataloaders, num_classes = load_data(image_size=IMAGE_SIZE,\n",
        "                                                     center_crop_size=CENTER_CROP_SIZE,\n",
        "                                                     dataset_dir_path=DATASET_DIR_PATH,\n",
        "                                                     train_dataset_dir_path=TRAINING_DATASET_DIR_NAME,\n",
        "                                                     validation_dataset_dir_path=VALIDATION_DATASET_DIR_NAME,\n",
        "                                                     test_dataset_dir_path=TEST_DATASET_DIR_NAME,\n",
        "                                                     num_workers_dataloader=NUM_WORKERS_DATALOADER,\n",
        "                                                     batch_size=BATCH_SIZE_STEP_ZERO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1TAeJYtMTtU"
      },
      "source": [
        "> Load only pre-trained model or load from checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5zOqfBmLYXy"
      },
      "outputs": [],
      "source": [
        "model = load_model(num_classes=num_classes, output_fc_units=OUTPUT_FC_UNITS, device=DEVICE, checkpoints_path=MODEL_CHECKPOINT_PATH, freeze_base_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ezX9t1OE3g"
      },
      "source": [
        "> Create learning loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmzy0y_mN8EP"
      },
      "outputs": [],
      "source": [
        "criterion, optimizer = define_loss_opt(learning_rate=LEARNING_RATE_STEP_ZERO, momentum=MOMENTUM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALwpDhsXP7iN"
      },
      "source": [
        "> Train model for the first phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9iHVnnJPfts"
      },
      "outputs": [],
      "source": [
        "model = train(num_epoch=NUM_EPOCHS_STEP_ZERO,\n",
        "          model=model,\n",
        "          train_dataset_dir_path=TRAINING_DATASET_DIR_NAME,\n",
        "          validation_dataset_dir_path=VALIDATION_DATASET_DIR_NAME,\n",
        "          dataloaders=dataloaders,\n",
        "          image_datasets=image_datasets,\n",
        "          optimizer=optimizer,\n",
        "          criterion=criterion,\n",
        "          device=DEVICE,\n",
        "          checkpoints_path=MODEL_CHECKPOINT_PATH,\n",
        "          step=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ9UitLJKvFB"
      },
      "source": [
        "## ***Phase 1: Train all layers***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLPq1idpWJOf"
      },
      "outputs": [],
      "source": [
        "image_datasets, dataloaders, num_classes = load_data(image_size=IMAGE_SIZE,\n",
        "                                                     center_crop_size=CENTER_CROP_SIZE,\n",
        "                                                     dataset_dir_path=DATASET_DIR_PATH,\n",
        "                                                     train_dataset_dir_path=TRAINING_DATASET_DIR_NAME,\n",
        "                                                     validation_dataset_dir_path=VALIDATION_DATASET_DIR_NAME,\n",
        "                                                     test_dataset_dir_path=TEST_DATASET_DIR_NAME,\n",
        "                                                     num_workers_dataloader=NUM_WORKERS_DATALOADER,\n",
        "                                                     batch_size=BATCH_SIZE_STEP_ONE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYq5FkfibliG"
      },
      "outputs": [],
      "source": [
        "model = load_model(num_classes=num_classes, output_fc_units=OUTPUT_FC_UNITS, device=DEVICE, checkpoints_path=MODEL_CHECKPOINT_PATH, freeze_base_layers=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_tv8Nt3btCf"
      },
      "outputs": [],
      "source": [
        "criterion, optimizer = define_loss_opt(learning_rate=LEARNING_RATE_STEP_ONE, momentum=MOMENTUM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruBgyRdEb0N7"
      },
      "outputs": [],
      "source": [
        "model = train(num_epoch=NUM_EPOCHS_STEP_ONE,\n",
        "          model=model,\n",
        "          train_dataset_dir_path=TRAINING_DATASET_DIR_NAME,\n",
        "          validation_dataset_dir_path=VALIDATION_DATASET_DIR_NAME,\n",
        "          dataloaders=dataloaders,\n",
        "          image_datasets=image_datasets,\n",
        "          optimizer=optimizer,\n",
        "          criterion=criterion,\n",
        "          device=DEVICE,\n",
        "          checkpoints_path=MODEL_CHECKPOINT_PATH,\n",
        "          step=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGEic46-cKuE"
      },
      "source": [
        "# **Evaluate Model Process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9B5RvFEnZhz"
      },
      "source": [
        "> Load dataset for model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngI5OFnkcQ-r"
      },
      "outputs": [],
      "source": [
        "image_datasets, dataloaders, num_classes = load_data(image_size=IMAGE_SIZE,\n",
        "                                                     center_crop_size=CENTER_CROP_SIZE,\n",
        "                                                     dataset_dir_path=DATASET_DIR_PATH,\n",
        "                                                     train_dataset_dir_path=TRAINING_DATASET_DIR_NAME,\n",
        "                                                     validation_dataset_dir_path=VALIDATION_DATASET_DIR_NAME,\n",
        "                                                     test_dataset_dir_path=TEST_DATASET_DIR_NAME,\n",
        "                                                     num_workers_dataloader=NUM_WORKERS_DATALOADER,\n",
        "                                                     batch_size=BATCH_SIZE_STEP_EVAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANPgde1zqWV6"
      },
      "outputs": [],
      "source": [
        "model = load_model(num_classes=num_classes, output_fc_units=OUTPUT_FC_UNITS, device=DEVICE, checkpoints_path=MODEL_CHECKPOINT_PATH, freeze_base_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "149RSvPfnxD1"
      },
      "source": [
        "\n",
        "\n",
        "> Evaluate model and show and return learning metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKyXvx7ZnwYk"
      },
      "outputs": [],
      "source": [
        "accuracy, precision, recall, f1, conf_matrix = evaluation(model=model, dataloaders=dataloaders, test_dataset_dir_path=TEST_DATASET_DIR_NAME, device=DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl9eqACllmwK"
      },
      "source": [
        "# **Inference from the loaded model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMJWBmG9n_rZ"
      },
      "outputs": [],
      "source": [
        "model = load_model(output_fc_units=OUTPUT_FC_UNITS, device=DEVICE, checkpoints_path=MODEL_CHECKPOINT_PATH, freeze_base_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLmhK2KRuLEd"
      },
      "source": [
        "> Predict a skin cancer image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epqrHoszl8Sp"
      },
      "outputs": [],
      "source": [
        "image_path = \"/content/drive/MyDrive/BSc Project/Skin Cancer Datasets/ISIC_2019_Dataset/Validation Dataset/melanoma/ISIC_0026115.jpg\"\n",
        "prediction(image_path=image_path, mapping_label_index=MAPPING_LABEL_INDEX)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}